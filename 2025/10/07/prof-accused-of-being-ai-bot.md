# [Prof accused of being AI bot](https://www.purdueexponent.org/campus/article_2d1826e2-2bfa-11ee-84c9-6f34496edb29.html)

This article was referenced by [Wikipedia's discussion about chatbot comments in discussions](../../../2025/10/07/wikipedia_chatbot_comments_in_discussions.md). It answered a question about a nuance of AI detection that must be taken into account when interacting with neurodivergent people.

## Is there a style of human writing that is easy to mistake for the output of an AI chatbot? 

Apparently so. Evidently, some autistic people write in a way that has been mistaken for AI output.

> Purdue professor Rua Mae Williams received an email they never expected to see: They were accused of being an artificial intelligence bot. “It’s not an AI. I’m just autistic," the professor of user experience and design said in response.

In recent years, people have gotten used to the prompt-response interaction style with a chatbot, and the frustration over tripping up against limitations of a chatbot is similarly something many people encounter daily. To the point, it seems, where people start mistaking interactions with humans for interactions with chatbots.

> The accusation came from a person who asked for a list of information about a research project.

Prepare for an AI accusation when the person writing the email treats it like a chatbot prompt and then gets frustrated with the response.

> The response to that was just “my apologies,” they said. AI detection software is not a reliable way to test for AI generated writing, Williams said, but people are still very suspicious. “Anytime (teachers) think something is weird,” they said, “well guess who’s the most likely to be considered weird.”

When a person who seems to have been frustrated with a chatbot in the past experienced a similar kind of frustration with a human, it can and sometimes does result in an AI accusation. Our society in general doesn't have much experience communicating with autistic people, but it has significant experience communicating with chatbots. Because of this, the writing produced by the former is often mistaken for that generated by the latter.

> Williams said they noticed the pattern affected their autistic friends as well. “We’re often critiqued for being disjointed, like (my friends’ work) is not linear,” they said, “or it’s too expansive, it’s not direct enough or focused enough.”

The AI writing style is not easy to describe, but most humans recognize it on the spot because it feels off to them. This is also how autistic writing feels to nonautistic people.

> We get into (longer) fights with reviewers about whether or not the way we write is on purpose and serves a rhetorical purpose.

Chatbots are known to be overly verbose, repeating the same thing many times over in different words. Autistic people do the same.

> Repetition is literally in the pathology of autism in clinical literature.
