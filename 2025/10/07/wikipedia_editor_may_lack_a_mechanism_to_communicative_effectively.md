# [Editor may lack a mechanism to communicative effectively](https://en.m.wikipedia.org/w/index.php?oldid=1266947801#Editor_may_lack_a_mechanism_to_communicative_effectively)

This discussion was referenced by [Wikipedia's discussion about chatbot comments in discussions](../../../2025/10/07/wikipedia_chatbot_comments_in_discussions.md). It answered two questions about using AI for work.

## Why should you not put LLM outputs into your writing?

LLMs have significant problems with plagiarism, misattribution of sources, incorrect information, etc. But they also make you sound like someone who should not be trusted.

> LLMs don't sound like aware intellectuals, they sound like marketing bullshiters.

## What to say to someone turning in chatbot-generated text for work?

Something along the lines of, "If you have a cognitive disability, trying to overcome it with AI is not a good strategy. AI is not an effective communicator. AI-generated text is disruptive in discussions." This is how a Wikipedian reacts to a user who have chosen to filter all of his communication with the community through an LLM chatbot.

> If they are unable to communicate using unaided cognition, and the technical adjunct they're using to assist them is also ineffective at communicating in a way in which our OI editors can interact, their contributions are having the effect of being disruptive.

Or something along the lines of, "AI chatbots do not follow the rules in our employee handbook." A Wikipedian made this point when justifying an indefinite ban on a Wikipedia contributor who uses AI chatbots in his contributions and discussions.

> The problem with LLMs is that they don't understand the rules of Wikipedia. A user who is copy/pasting LLM responses is unlikely to learn the rules of Wikipedia, precisely because the user trusts the LLM to provide adequate answers.
