# [AI Is Ruining Your Students’ Writing](https://www.chronicle.com/article/10-ways-ai-is-ruining-your-students-writing)

Wendy Laura Belcher, a professor of African literature at Princeton University, gives a lecture to her students trying to talk them out of having AI do their writing assignments for them. She summarized her lecture in this article, which was referenced by [Wikipedia's essay on spotting signs of AI writing](../../../2025/10/11/wikipedia-signs-of-ai-writing.md). It answered five questions about AI in the context of academic dishonesty.

## Why is the Princeton University professor of African literature giving her students a lecture on AI?

Because it's personal to her. AI is ruining the minds of her students.

> Producing a generation that can’t write — which means, in a profound way, a generation that can’t think — is something my heart can’t take.

## If LLMs have been trained on student writing of all grades, does a typical LLM output average to a C-grade student paper?

No, rather than averaging the quality of the paper, it averages everything interesting out of the paper.

> I never used to receive essays with banal arguments. I would get papers with no argument, or vague arguments, or totally off-base arguments, but never banal ones. Now I regularly get papers about the hero’s journey. The conflict between tradition and modernity. The individual against the community. How fixed boundaries between X and Y are destabilized by Z. Make it stop! LLMs are about predicting the next most likely word — which, by definition, is the most obvious. And literary analysis is precisely about what is not obvious.

Students don't write obvious things, but LLMs do. That's the difference between their outputs. AI writes in empty generalities.

> Bloated emptiness.

The overly safe content filters and the endless weasel words make the AI-generated ramblings devoid of meaning.

> Here’s an AI-assisted example from a student’s paper: “Africa is home to some of the world’s most diverse literary works.” That is a sentence. It is grammatically correct. It has no typos. It is snappily short. It is on topic for the course. And ... it means nothing. AI tossed together extremely common phrases — “home to” and “some of” and “world’s most.”

LLMs only follow the rules of syntax. They don't follow the semantics. "Diverse" is a synonym for "African" to an LLM even when it's in the African context, where African is not at all diverse.

> We all know what the AI — most likely developed in America — had in mind when it used the word “diverse.” It meant that African literary works have lots of Black characters. But Black people are not diverse in the Africa context, they are the norm.

## Is an LLM a good writer?

Not at all. It has a repetition penalty that forces it into "elegant" variation.

> AI-assisted papers often refer to something once by its proper name and then substitute it throughout the rest of the paper with referents. For instance, it will give the name of the epic’s hero, Sunjata, and then refer to him as the “main character,” and as the “protagonist,” the “central figure,” the “key player,” and so on. Each variation causes cognitive load for the reader: Are we still talking about the same person? This anti-repetition bias hinders the reader’s understanding. Now I can’t really blame AI. This terrible advice about varying words is regularly given in composition classes, especially at the middle- and high-school levels. And sure, I am all for varying verbs and adjectives, adverbs and conjunctions. No one wants to read a string of sentences repeating the adjective “compelling.” But AI tools always vary nouns as well — including that of the paper’s main subject. Indeed, they avoid repetition so much that they can’t keep a throughline. It’s why so many AI-assisted papers drift farther and farther from the announced subject, ending somewhere else entirely.

While human-written text with elegant variation is confusing to the reader, AI-generated text is confusing to both the reader and the "writer." The AI confuses itself. As it starts to run out of the synonyms for the subject of its writing, the AI starts recruiting words that no longer apply to the subject. Pick any AI-generated sentence, and you will likely see how the AI's attempts to recruit unnecessary words into its "essay" diminish its quality.

> "The Virgin Mary giving water to a dog in her shoe is a metaphor for mercy." But it’s not a metaphor for mercy, it is mercy itself. AI distorts meaning by sprinkling in literary terms.

Whereas repetition penalties force AI into "elegant" variation, its tendency to string together abstractions results in verbose meaningless.

> Many sentences in AI-generated papers consist of tossing a random literary term into a stream of Roman genitives (“x of y” phrases). Noun phrases are modular, so AI finds it easy to slot them into sentences and does so excessively.

When AI puts synthesis words into its outputs, it often presents correlation as causation.

> AI frequently misstates how one idea relates to another by suturing sentences together with common academic verbs like “highlights,” “underscores,” or “emphasizes.”

It is dangerous to randomly scatter synthesis words through a corpus of text because it could end up connecting concepts that may co-occur in the same context but that are otherwise unconnected.

> AI frequently turns what emerges from a certain context into what creates that context.

AI will also remove the interpreter. It will misattribute an action to an inanimate object or idea when it was really a human who took said action or thought up the idea.

> AI often generates sentences in which the text is doing something when, really, it is the human interpreter who is doing it through analysis. AI will take your ideas, erase your agency as the author, and present your texts (and abstractions) as agents.

## How to tell AI-generated writing from student writing? 

If the essay is overly inflated with evaluative adjectives, many of which don't fit, then it's likely AI-generated.

> Student papers never used to have a lot of adjectives. But AI-generated prose is hyper-adjectival — almost no noun passes without getting a positive or negative modifier.

## What to do if you're grading an essay that appears to be AI-generated?

AI-generated work suffers from a characteristic and well-documented set of problems. Tell the suspected AI plagiarizers that whether or not the problems in their writing are due to their use of AI, they need to be fixed before they can pass the class.

> If you get an essay that is banal, bloated, and meandering — much less one with an absent student interpreter and ill-connected ideas that are judgmental, racist, plagiarized, and/or factually wrong — simply stop grading, send the student this article, and ask them to rewrite. Tell them that you don’t know whether they used AI to do the assignment, and that’s not the point. What you do know is that their essay has typical AI flaws and the student must rewrite it without those flaws to earn a passing grade.
