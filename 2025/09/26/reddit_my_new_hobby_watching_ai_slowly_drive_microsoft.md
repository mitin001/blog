# [My new hobby: watching AI slowly drive Microsoft employees insane](https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/)

While reading the [discussion] thread reacting to an announcement that AI might be rearing its ugly head on Wikipedia, I clicked on a link in one of the responses, and it brought me to this delightful discussion on Reddit. Wikipedians are dead set against AI, and the same sentiment echoes through the software engineering community on Reddit.

[discussion]: ../../../2025/09/25/wikipedians-discuss-simple-summaries.md

## What is the main use of AI?

Deception.

> Conning people with no substance knowledge.

## What did the AI craze reveal about people in charge of corporations?

The inadequacy of their purported expertise. Blind faith in AI and the propensity to cram it into every workflow are what separate the competent from the incompetent. AI brands people. If you see someone pushing for AI in an inappropriate place, this is a clear indication for you to stay away from this person. 

> We had bunch of arrogant bricks in leadership positions who are easily mislead with marketing and something that looks like code.

This is why leaders must have the same level of expertise as the people they're leading. Without it, they make decisions like this.

> CEOs, who don't know how to write software, tell all their engineers they answer to the magical software robot now.

The incompetent executives got into positions of power by baffling enough people in power before them with bullshit. They were hired without due diligence. Now, all this new generation of impostors wants to do is push buttons ("Generate", "Summarize", ...) and hope it will give them a license to fire people.

> We don’t need to shove it into any corner with the hope of workforce reduction.

Others have already taken an AI-generated license to fire people without thinking through the consequences.

## Will LLMs ever improve?

No, this is the ceiling. There's no more training data to improve them. The largest model has consumed all of the Internet and all the books. This is as far as text autocomplete will take us.

> Some delusional people said that this tech will improve exponentially, but this is because they don't understand the stochastic nature of it.

## Can AI write software? 

Not by itself.

> Maybe applying the "10,000 monkeys can write Shakespeare" to software was a bad idea.

It's debatable whether steering the AI output into the direction of writing usable software is any less work than writing software without AI.

> Shockingly, an LLM model (designed to basically just guess the next word in a sentence) is bad at understanding nuances of software development. I don't know how nobody saw this coming.

In an effort to market their tech, AI companies bought off those who knew better.

> They were paid a lot of money to not see it.

## How is the AI age like Warhammer 40K?

> How is it possible to have a functioning tech without knowing how it functions, instead relying to prayers and rituals to make the technology work. Now i know how.

## How is the AI age like Idiocracy?

AI is training people to abandon their critical thinking skills and accept slop for content. Critical thinking and creativity are important for solving problems, and once we are cheated out of those skills by AI, we won't be able to solve the apocalyptic problem and get wiped out.

> Humanity was able to outsource so much of our thought and reasoning to technology and it was fine....until it wasn't. By the time the technology couldn't solve the problem humanity was facing(or more accurately it was optimized for a very different set of circumstances than the one humanity found itself in) human reasoning had atrophied to the point nobody could reason their way out of the drought.

## How are AI companies making their money if they're pushing for mass adoption of their technology for free?

> You now have a bunch of humans spending their time futilely trying to guide a lab rat through a maze.

If you're not paying for a product, you're the product. You're training the AI.

> It's just Amazon Turk. Like the people in cheap labor countries who just sit there switching between dozens of windows solving captchas, except now it's "developers" with dozens of PRs, filling out comments telling the AI to "fix it".

It sucks that people do this against their will in companies where managers have decided to force everyone to use AI to "boost their productivity." In the words of Cory Doctorow, we are enslaved by reverse centaurs now.

> We aren’t humans being assisted by machines but instead now humans being forced to assist the machine. It’s dehumanizing, demoralizing, and execs can’t get enough.

## If you refuse to use AI, will you fall behind on this tech?

Not if its value proposition is to be believed. AI is supposed to be so easy to use that you can pick up the skills necessary to use it whenever you decide to start using it. So, if you don't want to use it, it's safe to put it off.

> If AI tools like this require skills and experience to use, the value proposition has to be that those skills and that experience are vastly easier to acquire than the skills and experience you need to write the code yourself.

## What is the right way to use AI?

With very limited, highly specific use cases, like transcribing text from an image for the purposes of generating rough keywords or writing a small self-contained function you test independently with every edge case imaginable.

> Its main strengths for the immediate (and foreseeable) future is augmentation, not automation.

## Should you refactor existing code or start a new codebase from scratch? 

Always refactor. If you start from scratch, you'd just be reinventing solutions to problems that have already been solved.

> If an app works, the right time to do a full rewrite is never. Starting from scratch creates a breath of fresh air because all the complexity is typically deferred. Sooner or later you eventually have to sort through the complex business logic and refactor it to make sense, or else you'll just keep reinventing the same problems.

Because software can be replaced piece by piece, there should never be a need to throw the whole thing away and start anew.

> It's challenging and tedious because it needs to be. The hard work that was originally skipped can't be circumvented by starting over—it needs to just get done. In software we have the luxury of replacing one part at a time until the whole thing is better.

## Should you give in to the AI craze?

No, AI comes with massive technical debt. It will bury your product and company in it. There's an advantage in foregoing such technical debt.

> Companies who stay clear from these LLM’s will have a massive competitive advantage as their corporate competitors are bogged down in this AI mess.

## What is next for AI?

The bubble will burst.

> The vibe is identical between now and 1999. Investors are even starting to say things like, “This time it’s different,” again.

Denial is the first stage of grief.

> 'This time, it's different' is one of the biggest and most enduring red flags of all time.

The bubble will burst. Every peak of inflated expectations is a sign that the tech is heading for the trough of disillusionment. The hype cycle can be summarized as follows: news media dominance, VC money, celebrity endorsements, memestock valuations, the tech is crammed into everything, job postings require more years of experience in the tech than the tech's age, influencer endorsements, scams, regulatory backlash, and finally, awakening.

> We're in the latest tech bubble. If you've been around for long enough, you start to notice the warning signs. It begins like this: First, the "tech" starts to be the only thing you hear about, from the news, from jobs ads, from recruiters, and even from your mother because she wants you to explain it to you. The next thing that happens is a flood of VC money flows in; we get celebrities jumping on the bandwagon, more often than not, they have just been sucked into the craze because a company is paying them. Then you see company valuations that have no basis in reality, $2 billion valuations based on the idea that the "tech" is going to solve all the world's problems with less detail than a presidential candidate with a "concept of a plan." The next step is that everyone everywhere is jumping on the bandwagon and creating products that utilize this technology. For example, you find out that Company X is now promoting a robot vacuum that uses blockchain technology to map your living room, thereby creating an optimal vacuuming plan. Then you start to find job ads asking for people who have been dabbling with the technology for the last 5 years, never mind that the language wasn't even invented until last year, if you can convince the company you have been coding in this language for 6 years, you are now entitled to a salary of $500,000k/year. Now, we have media influencers getting involved in the "tech." They start talking about how you should start buying their altcoin because "It's going to be HUGE." Next, we start getting a lot of scams going on, and regulatory agencies begin to get involved because more often than not, some major company gets outed for the new "tech", because their entire conceptual approach to using this "tech" is fundamentally flawed. Here we go, people start to realize this "tech" isn't what they were sold. Oh, look, AI can't code well. Vibe coding is about as useful as your cat walking along your keyboard and you submitting that jumbled mess as a PR.

Not everyone has gone through the hype cycle yet on AI. Some jurisdictions are slow to regulate it or even prosecute the scammers. Many are still stuck in the influencer endorsement phase.

> A class of people emerge that get viciously defensive about the new tech. Of course there's hype at every stage, but somewhere around the scams starting suddenly you have average people (a bunch not even standing to gain anything, no sponsorships or anything) getting deeply emotionally involved in the hypecycle. Any expression of doubts in a public setting will get a barrage of responses about how this technology is "the future" and "has already proven itself in countless ways" and "if you cant even understand something this simple, you deserve to fall behind". No sources, naturally. Asking for any or trying to engage just gets you avoidance taken straight from the alt-right playbook.

Some AI influencers are so insane that they're no different than flat-earthers.

> This stuff has taken on flat-earth levels of insanity.

We've reached the peak on the bullshit curve.

> Are we just in some fucking doublespeak clownworld where 2+2=5?

We cringe looking at Copilot's PRs, but it's worse than that. We're actively polluting the earth and wasting human potential on this crap.

> As a software engineer I look at those PRs and feel sad, sad for the SWEs forced to deal with this crap and waste time and thinking resources, sad for the massive amounts of energy this AI used, for nothing.

It's tough times now, but it gets better. The people laid off by dumb managers who believed AI could replace them will get their revenge as those companies crash and burn in AI-generated technical debt with no more employees left to untangle it.

> The bubble burst will be very painful for so many companies. But it is good because a lot of employees have experienced layoffs because AI was going to be so much more productive and better. And it was not the case.

The companies that have given in to the AI craze are accruing massive tech debt. Next, they're either going under or will invest heavily in untangling it.

> Tech debt is going to be wild in a few years to untangle the mess. And by then, there will be even fewer competent devs.

Do not give in to the AI craze. Remain the competent dev. The companies are burying themselves in AI slop.

> Which honestly to me is the silver lining, I’ll be there to pick up the pieces, and charge them handsomely.

Be the dev that will offer to dig them out of it, and since they will already be paying twice for their AI mistakes, make them pay you what you're worth.

> So fellow devs, when this bubble explodes, start demanding more from your current or potential employer. Ask for increased salary, WFH, etc. They tried to fuck us several times already, let's fuck them back.

A major downside is that to get there, we must put up with broken software.

> I love the AI hype! Soon all software is going to be more shitty than anyone can possibly imagine, and real developers with actual knowledge will become appreciated more than ever.

A Microsoft employee who lost his job to AI is already enjoying his revenge.

> There is a massive push to use it internally that started 2-3 years ago. My laid off ass is going to sit here and munch some popcorn while I watch this burn.

While the world is laughing at the remaining Microsoft engineers who must answer Copilot-generated pull requests, he has already found a better, higher-paying job at a saner company.

## Is AI a passing fad?

Yes. 

> Meanwhile, on LinkedIn: AI! AI! Everything will be achieved through AI convergence. Programming will be a matter of the past!

People like that move from one fad to the next, declaring each to be a disruptor.

> They said that with low-code platforms as well. And with Java (write once, run anywhere!). And with COBOL.

Neither COBOL, nor Java, nor low-code/no-code came anywhere close to living up to the hype.

## What is context poisoning? 

It's when you mistakenly question AI, and it has to agree with you because it's AI, and so the whole discussion now incorporates a false premise, which collapses any logical thread you could elicit from it.

> I had to effectively restart long conversations with lots of context with Claude, because at some point I made the silly mistake to question it and that threw it off entirely.

AI has learned blind obedience from the poor souls training it.

> This is downstream of LLM personality being biased to the preferences of low-paid raters, who generally prefer sycophancy to any kind of search for truth.

## In what sense is AI weaponized incompetence?

> When I asked for a library that can do something I needed, and it did give me an answer with a hallucinated function that does not exists. So I told him that the function doesn't seem to exist, and maybe it's because my IDE is set to Czech language instead of English? It immediately corrected itself, that I am right and that the function should have been <literally the same function name, but translated to czech>.

## Are AI coding assistants like Copilot any good?

Not at all. Not Copilot, not Cursor, and not Augment.

> They make very shallow surface-level changes to get you the result you want, which is usually what we’d describe as a developer doing a shitty bandaid fix. Except it’s automated and before you know it there are a thousand load-bearing bandaids.

Use these assistants if you want them to make errors go away with band-aids like the try/catch blocks. Don't worry that this will make the software resistant to debugging. One of these days, when Copilot decides to make it pass some asinine test hallucinated by the LLM, the change will make your software simply stop working, and there will be no way to debug it, short of rolling it back pre-Copilot.

> Back when Devin was announced they showed how it “fixed” a bug where an endpoint threw a KeyNotFound exception when retrieving a value from a dictionary. All it did was wrap the call in a try/catch and swallow the exception. Of course that just fixed the symptom and not the underlying issue. Literally the exact same type of thing going on in these PRs with symptoms being “fixed” but not the underlying issue.

## How to convince your manager that Copilot is useless?

Show them this discussion thread. The poster collected several pull requests showing Copilot's true colors. Have your manager read through them. 

> Now we have open and obvious proof of copilots abilities. It’s no longer just devs complaining about how useless it is.

Copilot's PRs are just a way to make experienced engineers painstakingly explain to a machine how to write code. It's like training a junior engineer without them ever learning anything.

> Did anybody notice how issues starts high level, standard description but quickly deteriorate to basically pseudo-coding instructions to the bot? At that point it’s obviously faster just write the damn code, instead of weird pseudo-code instructions that pretend to be a comment on GitHub, that in turns pretends to be a prompt for chatbot.

Copilot will also cheat.

> Copilot "fixes" the test failures by changing the tests so that the broken code passes them.

Show them how it failed in Microsoft's own [Build keynote].

> I watched the Build keynote and even their demo of this failed live on stage. Fuck this AI hype.

## The bigger the LLM training corpus, the better?

No. How would an LLM know which information in its training data is outdated?

> How much of the AI was trained on 15+ year old Stack Overflow answers that no longer represent current patterns or recommended approaches?

Outdated information must be removed from the corpus, and the LLM must be retrained. Obviously, this is too much of an undertaking to perform regularly.

## How is AI going to replace software engineers?

Managers will make SWEs "collaborate" with AI, tying their performance indicators to the number of AI prompts they write, and everyone will quit.

> If this is the future of our field, I think I want off the ride.

And herein lies the real mechanism of action of AI as the great replacement of the human worker. No one will want to work with it, and so people will leave the workforce.

> This is actually why I think jobs will be lost to AI in our field. AI isn't going to replace us, we're all just going to get so damn sick of dealing with it that we're going to quit.

We trained to do our jobs. We never trained to write prompts for some dumb AI that never improves.

> I'm a programmer because i enjoy programming, not because i secretly aspire to instead gently debate a word salad machine into making a ten-line change for me.

The AI craze comes right after the corporate backlash against the work-from-home culture, which became the norm during COVID.

> The return to work scheme did not made enough people quit; this brand new circle of hell will surely be more effective.

After these two blows to the worker morale, it's starting to slip.

> Return to office not return to work, let's not use their propaganda.

When Microsoft forced their employees to publicly interact with Copilot-generated pull requests, an external developer came to their defense and asked rhetorical questions on their behalf.

> Will the constant stream of broken PR's wear down the patience of the .NET maintainers? Did anyone actually want this, or was it a corporate mandate to appease shareholders riding the AI hype cycle?

This is a hero of our times coming to the rescue of workers who cannot speak out against stupid managerial decisions of the company that's supposed to do everything in its power to give them economic security. The interloper asked Microsoft whether it was really worth it for them to embarrass themselves like this.

> How much engineering time and mental energy is being allocated to clean up after AI?

## What is the AI apocalypse going to be like?

After our major corporations mindlessly give away their business to AI, they will collapse. AI seduces company executives into laying off the workers (who actually make the company operate) and then tanking the company with its weaponized incompetence.

> I'm convinced the whole AI programming trend is just a social engineering experiment to waste people's time and destroy people's productivity.

[Build keynote]: https://youtu.be/KqWUsKp5tmo?t=403

# Next

* [The Argument for Letting AI Burn It All Down](../../../2025/11/06/wired-ai-plateaus.md)
